opendistro-es:
  elasticsearch:
    master:
      replicas: 3
      storageClassName: standard
      livenessProbe:
        tcpSocket:
          port: transport
        initialDelaySeconds: 180
        periodSeconds: 10

    data:
      replicas: 3
      javaOpts: "-Xms1228m -Xmx1228m"
      resources:
        limits:
          memory: 2G
        requests:
          memory: 2G
      storageClassName: standard

    client:
      replicas: 2
      javaOpts: "-Xms1228m -Xmx1228m"
      resources:
        limits:
          memory: 2G
        requests:
          memory: 2G
      ingress:
        enabled: false

    securityConfig:
      enabled: true
      configSecret: "logging-security-config"
      internalUsersSecret: "logging-accounts"

  kibana:
    config:
      elasticsearch.hosts: ["https://logging-opendistro-es-client-service:9200"]
      elasticsearch.username: "${ELASTICSEARCH_USERNAME}"
      elasticsearch.password: "${ELASTICSEARCH_PASSWORD}"
      elasticsearch.requestHeadersWhitelist:
        - "Authorization"
        - "securitytenant"
        - "x-forwarded-for"
        - "x-auth-request-user"
        - "x-proxy-roles"
      elasticsearch.ssl.verificationMode: "none"
      opendistro_security.auth.type: "openid"
      opendistro_security.cookie.secure: true
      opendistro_security.cookie.password: "${COOKIE_PASS}"
      opendistro_security.multitenancy.enabled: false
      opendistro_security.openid.client_id: "kibana"
      opendistro_security.openid.client_secret: "${OPENID_SECRET}"
      opendistro_security.openid.scope: "openid"
      opendistro_security.openid.logout_url: "https://roundtable.lsst.codes/logout"
      server.basePath: "/logs"
      server.rewriteBasePath: true
      server.host: "0.0.0.0"
      server.ssl.enabled: false

    elasticsearchAccount:
      secret: "logging-accounts"

    extraEnvs:
      - name: OPENID_SECRET
        valueFrom:
          secretKeyRef:
            name: "logging-accounts"
            key: openid-secret

    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
      hosts:
        - "roundtable.lsst.codes/logs"

fluentd-elasticsearch:
  elasticsearch:
    hosts: ["logging-opendistro-es-client-service:9200"]
    scheme: https
    sslVerify: false
    auth:
      enabled: true
      user: "logstash"
      # Get password from the logging-accounts secret.
      password: ""
  secret:
    - name: OUTPUT_PASSWORD
      secret_name: "logging-accounts"
      secret_key: "logstash-password"
  configMaps:
    useDefaults:
      containersInputConf: false
  extraConfigMaps:
    kubernetes.input.conf: |-
      <source>
        @id fluentd-containers.log
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/containers.log.pos
        tag raw.kubernetes.*
        read_from_head true
        <parse>
          @type multi_format
          <pattern>
            format json
            time_key time
            time_format %Y-%m-%dT%H:%M:%S.%NZ
          </pattern>
          <pattern>
            format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
            time_format %Y-%m-%dT%H:%M:%S.%N%:z
          </pattern>
        </parse>
      </source>
      # Detect exceptions in the log output and forward them as one log entry.
      <match raw.kubernetes.**>
        @id raw.kubernetes
        @type detect_exceptions
        remove_tag_prefix raw
        message log
        stream stream
        multiline_flush_interval 5
        max_bytes 500000
        max_lines 1000
      </match>
      # Concatenate multi-line logs
      #<filter **>
      <filter kubernetes.**>
        @id filter_concat
        @type concat
        key message
        multiline_end_regexp /\n$/
        separator ""
      </filter>
      # Enriches records with Kubernetes metadata
      <filter kubernetes.**>
        @id filter_kubernetes_metadata
        @type kubernetes_metadata
      </filter>
      # Fixes json fields in Elasticsearch
      <filter kubernetes.**>
        @id filter_parser
        @type parser
        key_name log
        reserve_data true
        remove_key_name_field true
        <parse>
          @type multi_format
          <pattern>
            format json
          </pattern>
          <pattern>
            format none
          </pattern>
        </parse>
      </filter>
