opendistro-es:
  elasticsearch:
    master:
      replicas: 3
      storageClassName: standard
      livenessProbe:
        tcpSocket:
          port: transport
        initialDelaySeconds: 180
        periodSeconds: 10

    data:
      replicas: 3
      javaOpts: "-Xms1g -Xmx1g"
      resources:
        limits:
          memory: 2G
        requests:
          memory: 2G
      storageClassName: standard

    client:
      replicas: 2
      javaOpts: "-Xms1g -Xmx1g"
      resources:
        limits:
          memory: 2G
        requests:
          memory: 2G
      ingress:
        enabled: false

    securityConfig:
      enabled: true
      configSecret: "logging-security-config"
      internalUsersSecret: "logging-accounts"

  kibana:
    config:
      elasticsearch.username: "${ELASTICSEARCH_USERNAME}"
      elasticsearch.password: "${ELASTICSEARCH_PASSWORD}"
      elasticsearch.requestHeadersWhitelist:
        - "Authorization"
        - "X-Forwarded-For"
        - "X-Auth-Request-User"
        - "X-Proxy-Roles"
      opendistro_security.auth.type: "proxy"
      opendistro_security.cookie.secure: true
      opendistro_security.cookie.password: "${COOKIE_PASS}"

    elasticsearchAccount:
      secret: "logging-accounts"

    ingress:
      enabled: true
      annotations:
        nginx.ingress.kubernetes.io/auth-method: "GET"
        nginx.ingress.kubernetes.io/auth-response-headers: "X-Auth-Request-User"
        nginx.ingress.kubernetes.io/auth-signin: "https://roundtable.lsst.codes/login"
        nginx.ingress.kubernetes.io/auth-url: "https://roundtable.lsst.codes/auth?scope=exec:admin"
        nginx.ingress.kubernetes.io/configuration-snippet: |
          proxy_set_header X-Proxy-Roles "all_access"
      hosts:
        - "roundtable.lsst.codes/logs"

fluentd-elasticsearch:
  elasticsearch:
    hosts: ["logging-opendistro-es-client-service:9200"]
    scheme: https
    sslVerify: false
    auth:
      enabled: true
      user: "logstash"
      # Get password from the logging-accounts secret.
      password: ""
  secret:
    - name: OUTPUT_PASSWORD
      secret_name: "logging-accounts"
      secret_key: "logstash-password"
  configMaps:
    useDefaults:
      containersInputConf: false
  extraConfigMaps:
    kubernetes.input.conf: |-
      <source>
        @id fluentd-containers.log
        @type tail
        path /var/log/containers/*.log
        pos_file /var/log/containers.log.pos
        tag raw.kubernetes.*
        read_from_head true
        <parse>
          @type multi_format
          <pattern>
            format json
            time_key time
            time_format %Y-%m-%dT%H:%M:%S.%NZ
          </pattern>
          <pattern>
            format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
            time_format %Y-%m-%dT%H:%M:%S.%N%:z
          </pattern>
        </parse>
      </source>
      # Detect exceptions in the log output and forward them as one log entry.
      <match raw.kubernetes.**>
        @id raw.kubernetes
        @type detect_exceptions
        remove_tag_prefix raw
        message log
        stream stream
        multiline_flush_interval 5
        max_bytes 500000
        max_lines 1000
      </match>
      # Concatenate multi-line logs
      #<filter **>
      <filter kubernetes.**>
        @id filter_concat
        @type concat
        key message
        multiline_end_regexp /\n$/
        separator ""
      </filter>
      # Enriches records with Kubernetes metadata
      <filter kubernetes.**>
        @id filter_kubernetes_metadata
        @type kubernetes_metadata
      </filter>
      # Fixes json fields in Elasticsearch
      <filter kubernetes.**>
        @id filter_parser
        @type parser
        key_name log
        reserve_data true
        remove_key_name_field true
        <parse>
          @type multi_format
          <pattern>
            format json
          </pattern>
          <pattern>
            format none
          </pattern>
        </parse>
      </filter>
